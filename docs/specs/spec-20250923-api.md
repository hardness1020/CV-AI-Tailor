# Tech Spec — API

**Version:** v1.0.0
**File:** docs/specs/spec-20250923-api.md
**Status:** Draft
**PRD:** `prd-20250923.md`
**Contract Versions:** API v1.0 • Schema v1.0 • Queue v1.0

## Overview & Goals

Build a robust REST API backend using Django DRF that handles artifact management, job description parsing, CV/cover letter generation, and document export. Target P95 ≤30s for CV generation, ≥99.5% availability, and support for 10,000 concurrent users with proper rate limiting and caching.

Links to latest PRD: `docs/prds/prd-20250923.md`

## Architecture (Detailed)

### Topology (frameworks)

```
┌─────────────────────────────────────────────────────────────────────────┐
│                      API Layer (Django DRF)                             │
│  ┌─────────────────┬─────────────────┬─────────────────┬─────────────┐  │
│  │  Auth & Users   │   Artifacts     │   Generation    │   Export    │  │
│  │   ViewSets      │    ViewSets     │    ViewSets     │  ViewSets   │  │
│  └─────────────────┼─────────────────┼─────────────────┼─────────────┘  │
└──────────────────┬─┼─────────────────┼─────────────────┼─────────────────┘
                   │ │                 │                 │
                   │ │                 │                 │
┌──────────────────▼─▼─────────────────▼─────────────────▼─────────────────┐
│                    Django Business Logic Layer                          │
│  ┌─────────────────┬─────────────────┬─────────────────┬─────────────┐  │
│  │  User Service   │ Artifact Service│ Matching Service│Export Service│  │
│  │                 │                 │                 │             │  │
│  └─────────────────┼─────────────────┼─────────────────┼─────────────┘  │
└──────────────────┬─┼─────────────────┼─────────────────┼─────────────────┘
                   │ │                 │                 │
       ┌───────────▼─▼─────────────────▼─────────────────▼───────────┐
       │                    Redis (Cache + Broker)                   │
       │  ┌─────────────┬─────────────┬─────────────────────────────┐ │
       │  │   Session   │    Cache    │        Celery Queues        │ │
       │  │   Store     │    Layer    │    (artifact, generation)   │ │
       │  └─────────────┴─────────────┴─────────────────────────────┘ │
       └─────────────────────┬───────────────────────────────────────┘
                             │
       ┌─────────────────────▼───────────────────────────────────────┐
       │                Celery Workers                               │
       │  ┌──────────────┬──────────────┬────────────────────────┐   │
       │  │   Artifact   │   Evidence   │     Generation         │   │
       │  │  Processor   │  Validator   │      Worker            │   │
       │  └──────────────┼──────────────┼────────────────────────┘   │
       └─────────────────┼──────────────┼────────────────────────────┘
                         │              │
┌────────────────────────▼──────────────▼────────────────────────────────┐
│                    PostgreSQL Database                                 │
│  ┌─────────────┬─────────────┬─────────────┬─────────────────────────┐ │
│  │ auth_user   │ artifacts   │ evidence    │ generated_documents     │ │
│  │ profiles    │ labels      │ links       │ export_logs             │ │
│  │ sessions    │ skills      │ validations │ job_descriptions        │ │
│  └─────────────┴─────────────┴─────────────┴─────────────────────────┘ │
└───────────────────────────────────────────────────────────────────────┘
```

### Component Inventory

| Component | Framework/Runtime | Purpose | Interfaces (in/out) | Depends On | Scale/HA | Owner |
|-----------|------------------|---------|-------------------|------------|----------|-------|
| API Gateway | Django + Gunicorn + uv | HTTP request routing, middleware | In: HTTP/HTTPS; Out: DB, Redis, Celery | Redis, PostgreSQL | 5+ replicas behind LB | Backend |
| Auth ViewSets | Django DRF + JWT | Authentication, user management | In: Auth requests; Out: JWT tokens, Redis sessions | Redis, PostgreSQL | Stateless, auto-scale | Backend |
| Artifact ViewSets | Django DRF | CRUD for artifacts and evidence | In: REST API calls; Out: DB queries, Celery tasks | PostgreSQL, Redis, Celery | Stateless, auto-scale | Backend |
| Generation ViewSets | Django DRF | CV/cover letter generation orchestration | In: Generation requests; Out: Celery tasks, cached results | Redis, Celery, PostgreSQL | Stateless, async processing | Backend |
| Export ViewSets | Django DRF | Document format export (PDF/Docx) | In: Export requests; Out: Binary file streams | PostgreSQL, Redis | CPU-intensive, separate scaling | Backend |
| Business Logic | Django Services | Core domain logic, validation | In: ViewSet calls; Out: Model operations | PostgreSQL, Redis | Embedded in API processes | Backend |
| Dependency Manager | uv | Python package management and virtual environments | In: pyproject.toml; Out: Installed packages | Python runtime | Development/deployment tool | Backend |
| Redis Cache | Redis 7 | API response caching, session storage | In: Cache operations; Out: Cached data | - | Primary + replica, persistent | DevOps |
| Redis Broker | Redis 7 | Celery task queue management | In: Task submissions; Out: Task delivery | - | Same instance as cache | DevOps |
| Celery Workers | Celery + Python + uv | Async task processing | In: Queue messages; Out: DB updates, external API calls | Redis, PostgreSQL, LLM APIs | Auto-scale by queue depth | Backend |
| PostgreSQL | PostgreSQL 15 | Primary data persistence | In: SQL queries; Out: ACID-compliant results | - | Primary + read replicas | DevOps |

## Interfaces & Data Contracts

### Authentication Endpoints
```
POST /api/v1/auth/register
Body: {email, password, first_name, last_name}
Response: 201 {user_id, email, access_token, refresh_token}

POST /api/v1/auth/login
Body: {email, password}
Response: 200 {user_id, access_token, refresh_token}

POST /api/v1/auth/refresh
Body: {refresh_token}
Response: 200 {access_token}

POST /api/v1/auth/logout
Headers: Authorization: Bearer <token>
Response: 204
```

### Artifact Management Endpoints
```
POST /api/v1/artifacts
Headers: Authorization: Bearer <token>
Body: {
  title: string,
  description: string,
  start_date: date,
  end_date: date?,
  technologies: string[],
  collaborators: string[],
  evidence_links: [{url: string, type: enum, description: string}]
}
Response: 202 {artifact_id, status: "processing", task_id}

GET /api/v1/artifacts
Headers: Authorization: Bearer <token>
Query: ?page=1&limit=20&label=<label_id>&tech=<tech_name>
Response: 200 {
  artifacts: [{
    id, title, description, start_date, end_date,
    technologies, labels, evidence_links, validation_status
  }],
  pagination: {page, limit, total, has_next}
}

PUT /api/v1/artifacts/{id}
PATCH /api/v1/artifacts/{id}
DELETE /api/v1/artifacts/{id}
```

### Label and Skill Management
```
POST /api/v1/labels
Body: {name: string, description: string, role_type: enum, artifact_ids: int[]}
Response: 201 {label_id, name, artifact_count}

GET /api/v1/labels
Response: 200 {labels: [{id, name, description, role_type, artifact_count}]}

GET /api/v1/skills/suggest
Query: ?query=<partial_skill_name>
Response: 200 {suggestions: [{name, category, frequency}]}
```

### Generation Endpoints
```
POST /api/v1/generate/cv
Body: {
  job_description: string,
  company_name: string,
  role_title: string,
  label_ids: int[],
  template_id: int?,
  custom_sections: object?
}
Response: 202 {generation_id, status: "processing", estimated_completion}

GET /api/v1/generate/cv/{id}
Response: 200 {
  id, status: enum, content: object, evidence_links: object[],
  created_at, completed_at, job_description_hash
}

POST /api/v1/generate/cover-letter
Body: {
  job_description: string,
  company_name: string,
  role_title: string,
  artifact_ids: int[],
  tone: enum
}
Response: 202 {generation_id, status: "processing"}
```

### Export Endpoints
```
POST /api/v1/export/{generation_id}
Body: {format: enum["pdf", "docx"], include_evidence: boolean, qr_codes: boolean}
Response: 202 {export_id, status: "processing"}

GET /api/v1/export/{export_id}
Response: 200 {
  Content-Type: application/pdf | application/vnd.openxmlformats-officedocument.wordprocessingml.document,
  Content-Disposition: attachment; filename="cv_generated.pdf"
}
```

### Error Response Format
```json
{
  "error": {
    "code": "VALIDATION_ERROR",
    "message": "Invalid request data",
    "details": {
      "field_errors": {
        "email": ["This field is required"],
        "evidence_links": ["URL validation failed for: https://invalid-url"]
      }
    },
    "request_id": "req_123456789"
  }
}
```

## Data & Storage

### Database Schema

#### Core Tables
```sql
-- Users and Authentication
CREATE TABLE auth_user (
    id SERIAL PRIMARY KEY,
    email VARCHAR(254) UNIQUE NOT NULL,
    password VARCHAR(128) NOT NULL,
    first_name VARCHAR(150),
    last_name VARCHAR(150),
    is_active BOOLEAN DEFAULT TRUE,
    date_joined TIMESTAMP DEFAULT NOW()
);

CREATE TABLE user_profiles (
    id SERIAL PRIMARY KEY,
    user_id INTEGER REFERENCES auth_user(id) ON DELETE CASCADE,
    timezone VARCHAR(50) DEFAULT 'UTC',
    preferences JSONB DEFAULT '{}',
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);

-- Artifacts and Evidence
CREATE TABLE artifacts (
    id SERIAL PRIMARY KEY,
    user_id INTEGER REFERENCES auth_user(id) ON DELETE CASCADE,
    title VARCHAR(255) NOT NULL,
    description TEXT,
    start_date DATE,
    end_date DATE,
    technologies TEXT[] DEFAULT '{}',
    collaborators TEXT[] DEFAULT '{}',
    metadata JSONB DEFAULT '{}',
    status VARCHAR(20) DEFAULT 'active',
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);

CREATE TABLE evidence_links (
    id SERIAL PRIMARY KEY,
    artifact_id INTEGER REFERENCES artifacts(id) ON DELETE CASCADE,
    url TEXT NOT NULL,
    link_type VARCHAR(50), -- github, live_app, paper, video, etc.
    description TEXT,
    validation_status VARCHAR(20) DEFAULT 'pending',
    last_validated TIMESTAMP,
    validation_error TEXT,
    created_at TIMESTAMP DEFAULT NOW()
);

-- Skills and Labels
CREATE TABLE skills (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) UNIQUE NOT NULL,
    category VARCHAR(50), -- technology, framework, domain, soft_skill
    normalized_name VARCHAR(100),
    frequency INTEGER DEFAULT 0,
    created_at TIMESTAMP DEFAULT NOW()
);

CREATE TABLE labels (
    id SERIAL PRIMARY KEY,
    user_id INTEGER REFERENCES auth_user(id) ON DELETE CASCADE,
    name VARCHAR(100) NOT NULL,
    description TEXT,
    role_type VARCHAR(50), -- engineer, pm, designer, researcher
    color VARCHAR(7) DEFAULT '#007bff',
    created_at TIMESTAMP DEFAULT NOW()
);

CREATE TABLE artifact_labels (
    artifact_id INTEGER REFERENCES artifacts(id) ON DELETE CASCADE,
    label_id INTEGER REFERENCES labels(id) ON DELETE CASCADE,
    PRIMARY KEY (artifact_id, label_id)
);

CREATE TABLE artifact_skills (
    artifact_id INTEGER REFERENCES artifacts(id) ON DELETE CASCADE,
    skill_id INTEGER REFERENCES skills(id) ON DELETE CASCADE,
    proficiency_level INTEGER DEFAULT 1, -- 1-5 scale
    PRIMARY KEY (artifact_id, skill_id)
);

-- Job Descriptions and Generations
CREATE TABLE job_descriptions (
    id SERIAL PRIMARY KEY,
    user_id INTEGER REFERENCES auth_user(id) ON DELETE CASCADE,
    content_hash VARCHAR(64) UNIQUE NOT NULL,
    raw_content TEXT NOT NULL,
    parsed_data JSONB, -- requirements, skills, company_info
    company_name VARCHAR(255),
    role_title VARCHAR(255),
    created_at TIMESTAMP DEFAULT NOW()
);

CREATE TABLE generated_documents (
    id SERIAL PRIMARY KEY,
    user_id INTEGER REFERENCES auth_user(id) ON DELETE CASCADE,
    job_description_id INTEGER REFERENCES job_descriptions(id),
    document_type VARCHAR(20), -- cv, cover_letter
    content JSONB NOT NULL,
    evidence_links JSONB DEFAULT '[]',
    generation_metadata JSONB DEFAULT '{}',
    status VARCHAR(20) DEFAULT 'completed',
    created_at TIMESTAMP DEFAULT NOW(),
    expires_at TIMESTAMP DEFAULT (NOW() + INTERVAL '90 days')
);

CREATE TABLE export_logs (
    id SERIAL PRIMARY KEY,
    user_id INTEGER REFERENCES auth_user(id) ON DELETE CASCADE,
    generated_document_id INTEGER REFERENCES generated_documents(id),
    format VARCHAR(10), -- pdf, docx
    file_size INTEGER,
    evidence_included BOOLEAN DEFAULT FALSE,
    qr_codes_included BOOLEAN DEFAULT FALSE,
    download_count INTEGER DEFAULT 0,
    created_at TIMESTAMP DEFAULT NOW()
);
```

#### Indexes for Performance
```sql
-- User artifact queries
CREATE INDEX idx_artifacts_user_created ON artifacts(user_id, created_at DESC);
CREATE INDEX idx_artifacts_technologies ON artifacts USING GIN(technologies);

-- Evidence validation
CREATE INDEX idx_evidence_validation_status ON evidence_links(validation_status, last_validated);
CREATE INDEX idx_evidence_artifact ON evidence_links(artifact_id);

-- Skills and matching
CREATE INDEX idx_skills_name_trgm ON skills USING GIN(name gin_trgm_ops);
CREATE INDEX idx_artifact_skills_lookup ON artifact_skills(skill_id, proficiency_level);

-- Generation queries
CREATE INDEX idx_generated_docs_user_type ON generated_documents(user_id, document_type, created_at DESC);
CREATE INDEX idx_job_descriptions_hash ON job_descriptions(content_hash);

-- Export tracking
CREATE INDEX idx_export_logs_user_date ON export_logs(user_id, created_at DESC);
```

#### Migration Strategy
```python
# 001_initial_schema.py
class Migration(migrations.Migration):
    initial = True
    dependencies = []

    operations = [
        # Create all tables with proper constraints
        # Add indexes for performance
        # Set up initial data (skill taxonomy seed)
    ]

# 002_add_full_text_search.py
class Migration(migrations.Migration):
    dependencies = [('core', '0001_initial')]

    operations = [
        migrations.RunSQL("CREATE EXTENSION IF NOT EXISTS pg_trgm;"),
        migrations.RunSQL("CREATE EXTENSION IF NOT EXISTS btree_gin;"),
        # Add full-text search indexes
    ]
```

### Dependency Management with uv

#### Project Structure
```
backend/
├── pyproject.toml          # Project metadata and uv configuration
├── uv.lock                 # Lockfile with exact dependency versions
├── requirements/
│   ├── base.txt           # Core API dependencies
│   ├── dev.txt            # Development tools
│   └── prod.txt           # Production-only dependencies
├── manage.py
└── cv_tailor/
    ├── settings/
    │   ├── base.py
    │   ├── development.py
    │   └── production.py
    └── ...
```

#### Dependency Configuration (pyproject.toml)
```toml
[project]
name = "cv-tailor-api"
version = "0.1.0"
dependencies = [
    "django>=4.2,<5.0",
    "djangorestframework>=3.14,<4.0",
    "celery>=5.3,<6.0",
    "redis>=5.0,<6.0",
    "psycopg2-binary>=2.9,<3.0",
    "gunicorn>=21.0,<22.0",
    "whitenoise>=6.5,<7.0",
    "django-cors-headers>=4.3,<5.0",
    "djangorestframework-simplejwt>=5.3,<6.0",
    "django-ratelimit>=4.1,<5.0",
    "django-extensions>=3.2,<4.0",
    "pillow>=10.0,<11.0",
    "requests>=2.31,<3.0",
    "python-decouple>=3.8,<4.0",
]

[project.optional-dependencies]
dev = [
    "pytest>=7.4,<8.0",
    "pytest-django>=4.5,<5.0",
    "pytest-cov>=4.1,<5.0",
    "black>=23.0,<24.0",
    "isort>=5.12,<6.0",
    "flake8>=6.0,<7.0",
    "mypy>=1.5,<2.0",
    "django-debug-toolbar>=4.2,<5.0",
    "factory-boy>=3.3,<4.0",
    "pre-commit>=3.4,<4.0",
]
prod = [
    "sentry-sdk>=1.30,<2.0",
    "django-health-check>=3.17,<4.0",
    "django-prometheus>=2.3,<3.0",
]

[tool.uv]
dev-dependencies = [
    "pytest>=7.4",
    "black>=23.0",
    "mypy>=1.5",
]
```

#### Development Workflow
```bash
# Initial setup
uv sync                     # Install all dependencies including dev
uv sync --frozen           # Install from lockfile only (CI/production)
uv sync --group prod       # Install production dependencies only

# Development commands
uv run python manage.py runserver
uv run python manage.py migrate
uv run python manage.py test
uv run celery -A cv_tailor worker -l info

# Dependency management
uv add django-storages      # Add new dependency
uv add --dev pytest-mock   # Add development dependency
uv remove unused-package   # Remove dependency
uv lock                    # Update lockfile
```

## Reliability & SLIs/SLOs

### Service Level Indicators
- **API Availability:** Percentage of successful HTTP responses (non-5xx)
- **Response Latency:** P50, P95, P99 response times for each endpoint group
- **Generation Success Rate:** Percentage of successful CV/cover letter generations
- **Evidence Validation Rate:** Percentage of evidence links that remain valid

### Service Level Objectives
- **Availability:** ≥99.5% for core API endpoints (auth, artifacts, generation status)
- **Latency Targets:**
  - Authentication: P95 ≤500ms
  - Artifact CRUD: P95 ≤1s
  - Generation initiation: P95 ≤2s
  - CV generation completion: P95 ≤30s
  - Export generation: P95 ≤10s
- **Generation Success Rate:** ≥95% for valid inputs
- **Data Consistency:** ≥99.9% artifact-evidence link integrity

### Reliability Mechanisms
```python
# Circuit Breaker for LLM API
from django_circuit_breaker import CircuitBreaker

@CircuitBreaker(
    failure_threshold=5,
    timeout=60,
    expected_exception=LLMAPIException
)
def call_llm_api(prompt):
    # LLM API call logic
    pass

# Rate Limiting
from django_ratelimit import ratelimit

@ratelimit(key='user', rate='100/h', method='POST')
def artifact_create_view(request):
    # Artifact creation logic
    pass

# Caching Strategy
from django.core.cache import cache

def get_user_artifacts(user_id, filters):
    cache_key = f"artifacts:{user_id}:{hash(str(filters))}"
    cached_result = cache.get(cache_key)
    if cached_result:
        return cached_result

    result = Artifact.objects.filter(user_id=user_id, **filters)
    cache.set(cache_key, result, timeout=300)  # 5 minutes
    return result
```

## Security & Privacy

### Authentication & Authorization
```python
# JWT Configuration
JWT_AUTH = {
    'JWT_EXPIRATION_DELTA': timedelta(hours=24),
    'JWT_REFRESH_EXPIRATION_DELTA': timedelta(days=7),
    'JWT_ALGORITHM': 'HS256',
    'JWT_ALLOW_REFRESH': True,
}

# Permission Classes
class IsOwnerOrReadOnly(permissions.BasePermission):
    def has_object_permission(self, request, view, obj):
        return obj.user == request.user

# Rate Limiting by User Role
RATELIMIT_RATES = {
    'authenticated': '1000/h',
    'anonymous': '100/h',
    'premium': '5000/h',
}
```

### Data Protection
```python
# Evidence Link Encryption
from cryptography.fernet import Fernet

class EncryptedEvidenceLink(models.Model):
    encrypted_url = models.BinaryField()

    def set_url(self, url):
        cipher = Fernet(settings.EVIDENCE_ENCRYPTION_KEY)
        self.encrypted_url = cipher.encrypt(url.encode())

    def get_url(self):
        cipher = Fernet(settings.EVIDENCE_ENCRYPTION_KEY)
        return cipher.decrypt(self.encrypted_url).decode()

# PII Handling
class UserProfile(models.Model):
    # No PII stored beyond email
    preferences = models.JSONField(default=dict)  # Anonymous preferences only

    def anonymize(self):
        """GDPR deletion - remove all identifying data"""
        self.user.email = f"deleted_{self.user.id}@example.com"
        self.user.first_name = ""
        self.user.last_name = ""
        self.user.save()
```

### Audit Logging
```python
import structlog

audit_logger = structlog.get_logger("audit")

class AuditMiddleware:
    def __init__(self, get_response):
        self.get_response = get_response

    def __call__(self, request):
        start_time = time.time()
        response = self.get_response(request)

        audit_logger.info(
            "api_request",
            user_id=getattr(request.user, 'id', None),
            method=request.method,
            path=request.path,
            status_code=response.status_code,
            duration_ms=int((time.time() - start_time) * 1000),
            user_agent=request.META.get('HTTP_USER_AGENT', ''),
            ip_address=get_client_ip(request)
        )
        return response
```

## Evaluation Plan

### API Testing Strategy
```python
# Load Testing with Locust
from locust import HttpUser, task, between

class CVGenerationUser(HttpUser):
    wait_time = between(1, 3)

    def on_start(self):
        # Login and get auth token
        pass

    @task(3)
    def list_artifacts(self):
        self.client.get("/api/v1/artifacts")

    @task(1)
    def generate_cv(self):
        self.client.post("/api/v1/generate/cv", json={
            "job_description": "Software Engineer position...",
            "company_name": "TechCorp",
            "role_title": "Senior Software Engineer"
        })

# Integration Tests
class CVGenerationAPITest(APITestCase):
    def test_end_to_end_cv_generation(self):
        # Create user, upload artifact, generate CV, export PDF
        user = self.create_test_user()
        artifact = self.create_test_artifact(user)
        generation = self.generate_cv(user, artifact)
        export = self.export_pdf(generation)
        self.assertIsNotNone(export.content)
```

### Quality Metrics
- **API Response Accuracy:** JSON schema validation for all endpoints
- **Data Integrity:** Foreign key constraints, transaction rollback testing
- **Performance Benchmarks:** Response time regression testing
- **Security Testing:** OWASP Top 10 vulnerability scanning

## Rollout & Ops Impact

### Feature Flags
```python
# Feature Flag Integration
from django_feature_flags import feature_required

@feature_required('api.cv_generation.enabled')
def cv_generation_view(request):
    # CV generation logic
    pass

# Database Feature Flags
class FeatureFlag(models.Model):
    name = models.CharField(max_length=100, unique=True)
    enabled = models.BooleanField(default=False)
    rollout_percentage = models.IntegerField(default=0)
    user_whitelist = models.JSONField(default=list)
```

### Monitoring & Observability
```python
# Prometheus Metrics
from prometheus_client import Counter, Histogram, Gauge

api_requests_total = Counter(
    'api_requests_total',
    'Total API requests',
    ['method', 'endpoint', 'status']
)

cv_generation_duration = Histogram(
    'cv_generation_duration_seconds',
    'CV generation duration'
)

active_celery_tasks = Gauge(
    'celery_active_tasks',
    'Number of active Celery tasks',
    ['queue']
)
```

## Risks & Rollback

### Technical Risks
1. **Database Performance Degradation**
   - Risk: Complex queries slow down under load
   - Detection: Query monitoring, slow query logs
   - Mitigation: Query optimization, read replicas, caching
   - Rollback: Revert to simpler queries, scale database

2. **LLM API Rate Limiting**
   - Risk: External API limits block generations
   - Detection: API error rate monitoring
   - Mitigation: Multiple providers, request queuing
   - Rollback: Template-based generation fallback

3. **Memory Leaks in Celery Workers**
   - Risk: Workers consume excessive memory
   - Detection: Memory usage monitoring
   - Mitigation: Worker restart cycles, memory limits
   - Rollback: Reduce worker concurrency

### Data Migration Risks
```python
# Safe Migration Pattern
class Migration(migrations.Migration):
    atomic = False  # Large table migrations

    def forwards_func(apps, schema_editor):
        # Chunked data migration
        Model = apps.get_model('app', 'Model')
        batch_size = 1000

        for i in range(0, Model.objects.count(), batch_size):
            batch = Model.objects.all()[i:i+batch_size]
            # Process batch
            time.sleep(0.1)  # Avoid overwhelming DB

    operations = [
        migrations.RunPython(forwards_func, reverse_func),
    ]
```

## Open Questions

1. **Caching Strategy:** Redis vs database-level caching for artifact queries
2. **File Storage:** Local storage vs S3 for temporary export files
3. **WebSocket Integration:** Real-time generation progress updates
4. **API Versioning:** URL-based vs header-based versioning strategy
5. **Internationalization:** API response localization requirements

## Changelog

- 2025-09-23: Draft created; REST API design completed; authentication flow defined; database schema specified; caching and reliability patterns established; uv dependency management integration added